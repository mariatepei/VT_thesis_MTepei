{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ePj0Gly9jJ0W"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install torch\n",
        "!pip install librosa\n",
        "!pip install soundfile"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## This notebook contains everything necessary to perform batch transcriptions using the imported checkpoints. The current imports correspond to the fine-tuned versions, which can be found on my HF account."
      ],
      "metadata": {
        "id": "Cr28W6Jc41Ea"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import WhisperForConditionalGeneration, WhisperProcessor\n",
        "import librosa\n",
        "import soundfile as sf"
      ],
      "metadata": {
        "id": "cFnLI6vukY5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "rJ1B3YGbm6s3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "PKhkRexUqH2i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import fine-tuned checkpoints\n",
        "model_names = {\n",
        "    \"base\": \"mariatepei/whisper-base-synthetic_model\",\n",
        "    \"small\": \"mariatepei/whisper-small-synthetic_model\",\n",
        "    \"medium\": \"mariatepei/whisper-medium-synthetic_model\",\n",
        "    \"large\": \"mariatepei/whisper-large-synthetic_model\"\n",
        "}\n",
        "\n",
        "models = {}\n",
        "processors = {}\n",
        "\n",
        "for size, model_name in model_names.items():\n",
        "  processor = WhisperProcessor.from_pretrained(model_name)\n",
        "  model = WhisperForConditionalGeneration.from_pretrained(model_name)\n",
        "  models[size] = model\n",
        "  processors[size] = processor\n"
      ],
      "metadata": {
        "id": "5sK_t3DSlM5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_folder_path = \"/content/drive/My Drive/test\""
      ],
      "metadata": {
        "id": "QXbCmhDXmY7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for audio_file in os.listdir(test_folder_path):\n",
        "  if audio_file.endswith(\".wav\"):\n",
        "    audio_file_path = os.path.join(test_folder_path, audio_file)\n",
        "    audio_input, sample_rate = librosa.load(audio_file_path, sr = 16000)\n",
        "\n",
        "    for size in model_names.keys():\n",
        "      processor = processors[size]\n",
        "      model = models[size]\n",
        "\n",
        "      input_features = processor(audio_input, sampling_rate = sample_rate, return_tensors = \"pt\").input_features\n",
        "      # Specify the language and task, otherwise whisper will predict it (often wrongly)\n",
        "      forced_decoder_ids = processor.get_decoder_prompt_ids(language=\"dutch\", task=\"transcribe\")\n",
        "      predicted_ids = model.generate(input_features, forced_decoder_ids=forced_decoder_ids)\n",
        "\n",
        "      transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)[0]\n",
        "      transcription_file_path = os.path.join(test_folder_path, f\"{audio_file}_transcription_n_{size}.txt\")\n",
        "\n",
        "      with open(transcription_file_path, \"w\", encoding = \"utf8\") as f:\n",
        "        f.write(transcription)\n",
        "\n",
        "      print(f\"Transcription for {audio_file} using {size} model saved to {transcription_file_path}\")"
      ],
      "metadata": {
        "id": "jJtcckbbnUN_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "lqnNkmFM4zz9"
      }
    }
  ]
}